{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "\n",
    "    def train(self, dataframe, neurons_in_first_layer = 4, test_size = 0.2,iterations = 20000,learning_rate = 0.01):\n",
    "\n",
    "        self.df = dataframe\n",
    "        self.neurons_in_first_layer = neurons_in_first_layer\n",
    "        \n",
    "        self.x = self.df.iloc[:, :-1]\n",
    "        self.y = self.df.iloc[:,-1]\n",
    "\n",
    "        # Spliting data into training set and test set\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.x, self.y, test_size=test_size, random_state=42)\n",
    "\n",
    "        # converting x_train from dataframe format to numpy format for easier usage.\n",
    "        self.x_train = self.x_train.to_numpy()\n",
    "        self.y_train = self.y_train.to_numpy()\n",
    "\n",
    "        # Providing random values for Weights and Biases between -5 and 5\n",
    "        self.initialize_weights()\n",
    "\n",
    "        # Starting gradient decent\n",
    "        iter = 0\n",
    "\n",
    "        tolerance = 1e-3\n",
    "\n",
    "        while not (not ((np.linalg.norm(self.dW1()) > tolerance) and (np.linalg.norm(self.dW2()) > tolerance)) or not iter< iterations):\n",
    "            self.gradient_descent(learning_rate=learning_rate)\n",
    "            iter += 1\n",
    "            # print(f\"\\n\\niter = {iter}\")\n",
    "            # print(f\"self.dW1 = {self.dW1()}\")\n",
    "            # print(f\"self.dW2 = {self.dW2()}\")\n",
    "        print(f\"\\n\\niter = {iter}\")\n",
    "        print(f\"self.dW1 = {self.dW1()}\")\n",
    "        print(f\"self.dW2 = {self.dW2()}\")\n",
    "        \n",
    "\n",
    "    def initialize_weights(self):\n",
    "        # generating initial guess for W matrix\n",
    "        np.random.seed(seed=6)\n",
    "        self.W1 = 10 * np.random.rand(self.neurons_in_first_layer,self.x_train.shape[1]) - 5\n",
    "        self.W2 = 10 * np.random.rand(1,self.neurons_in_first_layer) - 5\n",
    "\n",
    "        # generating initial guess for b matrix\n",
    "        self.b1 = 10 * np.random.rand(self.neurons_in_first_layer,1) - 5\n",
    "        self.b2 = 10 * np.random.rand(1,1) - 5\n",
    "\n",
    "    def tanh(self,x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def d_tanh(self,x):\n",
    "        return 1 - np.square(np.tanh(x))\n",
    "    \n",
    "    def logloss(self,y, a):\n",
    "        return -(y*np.log(a) + (1-y)*np.log(1-a))\n",
    "\n",
    "    def d_logloss(self,y, a):\n",
    "        return (a - y)/(a*(1 - a))\n",
    "\n",
    "    def gradient_descent(self,learning_rate):\n",
    "        # Updating the value of the weights\n",
    "        self.W1 = self.W1 - (learning_rate * self.dW1())\n",
    "        self.W2 = self.W2 - (learning_rate * self.dW2())\n",
    "\n",
    "        # Updating the value of the bias\n",
    "        self.b1 = self.b1 - (learning_rate * self.db1())\n",
    "        self.b2 = self.b2 - (learning_rate * self.db2())\n",
    "\n",
    "\n",
    "    def Z1(self):\n",
    "        return np.dot(self.W1,self.x_train.T) + self.b1\n",
    "    \n",
    "    def Z2(self):\n",
    "        return np.dot(self.W2,self.a1()) + self.b2\n",
    "\n",
    "    def Z(self,W,x_T,b):\n",
    "        '''\n",
    "        z = (W * x) + b\n",
    "        Only initially, when input parameters are passed as x_train,\n",
    "        we have to transpose it while giving it in the function,\n",
    "        like as follows,\n",
    "        -> z(W = W1 , x_T = x_train.T , b = b1)\n",
    "\n",
    "        Else for hidden layers,\n",
    "        pass x_T normally with giving any transpose to a1,\n",
    "        like as follows,\n",
    "        -> z(W = W2 , x_T = a1 , b = b2)\n",
    "\n",
    "        THERE IS NO NEED FOR CONVERT b FROM nx1 TO nxm,\n",
    "        CODE ->\n",
    "        a = np.array([[1,2,3,4],\n",
    "             [5,6,7,8],\n",
    "             [9,10,11,12],])\n",
    "        b = np.array([[5],\n",
    "             [6],\n",
    "             [7],])\n",
    "\n",
    "        print(a+b)  \n",
    "\n",
    "        OUTPUT ->\n",
    "        [[ 6  7  8  9]\n",
    "        [11 12 13 14]\n",
    "        [16 17 18 19]]\n",
    "\n",
    "        '''\n",
    "        return np.dot(W,x_T) + b\n",
    "\n",
    "\n",
    "    def a(self,z):\n",
    "        return self.tanh(z)  \n",
    "\n",
    "    def a1(self):\n",
    "        return self.tanh(self.Z1()) \n",
    "    \n",
    "    def a2(self):\n",
    "        return self.tanh(self.Z2())\n",
    "    \n",
    "    def dZ2(self):\n",
    "        '''\n",
    "        Remember that, here, y_train is a 1xm matrix, not a mx1 matrix,\n",
    "        so dont forget to convert self.y_train from mx1 to 1xm.\n",
    "        '''\n",
    "        dA = self.d_logloss(self.y_train,self.a2())\n",
    "        dZ2 = np.multiply(self.d_tanh(self.Z2()), dA)\n",
    "        return dZ2\n",
    "    \n",
    "    def dW2(self):\n",
    "        # print(self.x_train.shape)\n",
    "        dW2 = 1/self.dZ2().shape[1] * np.dot(self.dZ2(), self.a1().T)\n",
    "        return dW2\n",
    "    \n",
    "    def db2(self):\n",
    "        db2 = 1/self.dZ2().shape[1] * np.sum(self.dZ2(), axis=1, keepdims=True)\n",
    "        return db2\n",
    "    \n",
    "    def dZ1(self):\n",
    "        dA = np.dot(self.W2.T, self.dZ2())\n",
    "        dZ2 = np.multiply(self.d_tanh(self.Z1()), dA)\n",
    "        return dZ2\n",
    "\n",
    "    \n",
    "    def dW1(self):\n",
    "        dW1 = 1/self.dZ1().shape[1] * np.dot(self.dZ1(), self.x_train)\n",
    "        return dW1\n",
    "    \n",
    "    def db1(self):\n",
    "        db1 = 1/self.dZ1().shape[1] * np.sum(self.dZ1(), axis=1, keepdims=True)\n",
    "        return db1\n",
    "    \n",
    "    def test_model(self):\n",
    "        Z1 = self.Z(b=self.b1,W=self.W1,x_T=self.x_test.T,)\n",
    "        a1 = self.a(z=Z1)\n",
    "        Z2 = self.Z(b=self.b2,W=self.W2,x_T=a1)\n",
    "        a2 = self.a(z=Z2)\n",
    "\n",
    "        self.predicted_correct = 0\n",
    "        self.predicted_wrong = 0\n",
    "        self.true_positives = 0\n",
    "        self.true_negatives = 0\n",
    "        self.false_positives = 0\n",
    "        self.false_negatives = 0\n",
    "\n",
    "        for i,j in zip(self.y_test,a2[0]):\n",
    "            # print(f\"i = {i}  j = {j}\")\n",
    "            if j>0:\n",
    "                j=1\n",
    "            else:\n",
    "                j=0\n",
    "            \n",
    "            if i == j:\n",
    "                self.predicted_correct+=1\n",
    "                if i == 1:\n",
    "                    self.true_positives+=1\n",
    "                else:\n",
    "                    self.true_negatives+=1\n",
    "            else:\n",
    "                self.predicted_wrong+=1\n",
    "                if j == 1:\n",
    "                    self.false_positives+=1\n",
    "                else:\n",
    "                    self.false_negatives+=1\n",
    "\n",
    "        print(f\"The accuracy of the model is {(self.predicted_correct/(self.predicted_correct + self.predicted_wrong))*100} %.\")\n",
    "        try:\n",
    "            self.precision = (self.true_positives/(self.true_positives + self.false_positives))\n",
    "            print(f\"The Precision of the model is {self.precision*100} %.\")\n",
    "        except:\n",
    "            print(f\"Precision can't be calculated.\")\n",
    "        \n",
    "        try:\n",
    "            self.recall = (self.true_positives/(self.true_positives + self.false_negatives))\n",
    "            print(f\"The Recall/Sensitivity of the model is {self.recall*100} %.\")\n",
    "        except:\n",
    "            print(f\"Prediction can't be calculated.\")\n",
    "\n",
    "        try:\n",
    "            self.specificity = (self.true_negatives/(self.true_negatives + self.false_positives))\n",
    "            print(f\"The Specificity of the model is {self.specificity*100} %.\")\n",
    "        except:\n",
    "            print(f\"Specificity can't be calculated.\")\n",
    "\n",
    "        try:\n",
    "            self.f1_score = 2 * ((self.precision * self.recall)/(self.precision + self.recall))\n",
    "            print(f\"The F1-Score of the model is {self.f1_score}\")\n",
    "        except:\n",
    "            print(f\"F1-Score can't be calculated.\")\n",
    "    \n",
    "    def cost(self):\n",
    "        print(self.a2())\n",
    "        loss = -np.mean(self.y_train * np.log(self.a2().T) + (1 - self.y_train) * np.log(1 - self.a2().T))\n",
    "        print(loss)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iter = 9837\n",
      "self.dW1 = [[ 7.05875539e-07  2.15142089e-06]\n",
      " [ 2.84922440e-04  1.44449206e-04]\n",
      " [-3.70408771e-04  8.72079178e-04]]\n",
      "self.dW2 = [[-0.00090105 -0.00247379  0.00638234]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Logistic_regression_ls.csv\")\n",
    "neu1 = NeuralNetwork()\n",
    "neu1.train(dataframe=df,neurons_in_first_layer=3,test_size=0.2,iterations=10000,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 100.0 %.\n",
      "The Precision of the model is 100.0 %.\n",
      "The Recall/Sensitivity of the model is 100.0 %.\n",
      "The Specificity of the model is 100.0 %.\n",
      "The F1-Score of the model is 1.0\n"
     ]
    }
   ],
   "source": [
    "neu1.test_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
